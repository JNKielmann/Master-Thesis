{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "from gensim.summarization.bm25 import BM25\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import spacy\n",
    "\n",
    "\n",
    "from bm25_retrieval import BM25Retrieval\n",
    "from evaluation import average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2150066425</td>\n",
       "      <td>are we ready for autonomous driving the kitti vision benchmark suite today visual recognition systems are still rarely employed in robotics applications perhaps one of the main reasons for this is the lack of demanding benchmarks that mimic such scenarios in this paper we take advantage of our autonomous driving platform to develop novel challenging benchmarks for the tasks of stereo optical flow visual odometry slam and 3d object detection our recording platform is equipped with four high resolution video cameras a velodyne laser scanner and a state of the art localization system our benchmarks comprise stereo and optical flow image pairs stereo visual odometry sequences of km length and more than 200k 3d object annotations captured in cluttered scenarios up to cars and pedestrians are visible per image results from state of the art algorithms reveal that methods ranking high on established datasets such as middlebury perform below average when being moved outside the laboratory t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2133151341</td>\n",
       "      <td>the hitran molecular spectroscopic database this paper describes the contents of the edition of the hitran molecular spectroscopic compilation the new edition replaces the previous hitran edition of and its updates during the intervening years the hitran molecular absorption compilation is composed of five major components the traditional line by line spectroscopic parameters required for high resolution radiative transfer codes infrared absorption cross sections for molecules not yet amenable to representation in a line by line form collision induced absorption data aerosol indices of refraction and general tables such as partition sums that apply globally to the data the new hitran is greatly extended in terms of accuracy spectral coverage additional absorption phenomena added line shape formalisms and validity moreover molecules isotopologues and perturbing gases have been added that address the issues of atmospheres beyond the earth of considerable note experimental ir cross se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2115579991</td>\n",
       "      <td>vision meets robotics the kitti dataset we present a novel dataset captured from a vw station wagon for use in mobile robotics and autonomous driving research in total we recorded hours of traffic scenarios at hz using a variety of sensor modalities such as high resolution color and grayscale stereo cameras a velodyne 3d laser scanner and a high precision gps imu inertial navigation system the scenarios are diverse capturing real world traffic situations and range from freeways over rural areas to inner city scenes with many static and dynamic objects our data is calibrated synchronized and timestamped and we provide the rectified and raw image sequences our dataset also contains object labels in the form of 3d tracklets and we provide online benchmarks for stereo optical flow object detection and other tasks this paper describes our recording platform the data format and the utilities that we provide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 abstract\n",
       "0  2150066425  are we ready for autonomous driving the kitti vision benchmark suite today visual recognition systems are still rarely employed in robotics applications perhaps one of the main reasons for this is the lack of demanding benchmarks that mimic such scenarios in this paper we take advantage of our autonomous driving platform to develop novel challenging benchmarks for the tasks of stereo optical flow visual odometry slam and 3d object detection our recording platform is equipped with four high resolution video cameras a velodyne laser scanner and a state of the art localization system our benchmarks comprise stereo and optical flow image pairs stereo visual odometry sequences of km length and more than 200k 3d object annotations captured in cluttered scenarios up to cars and pedestrians are visible per image results from state of the art algorithms reveal that methods ranking high on established datasets such as middlebury perform below average when being moved outside the laboratory t...\n",
       "1  2133151341  the hitran molecular spectroscopic database this paper describes the contents of the edition of the hitran molecular spectroscopic compilation the new edition replaces the previous hitran edition of and its updates during the intervening years the hitran molecular absorption compilation is composed of five major components the traditional line by line spectroscopic parameters required for high resolution radiative transfer codes infrared absorption cross sections for molecules not yet amenable to representation in a line by line form collision induced absorption data aerosol indices of refraction and general tables such as partition sums that apply globally to the data the new hitran is greatly extended in terms of accuracy spectral coverage additional absorption phenomena added line shape formalisms and validity moreover molecules isotopologues and perturbing gases have been added that address the issues of atmospheres beyond the earth of considerable note experimental ir cross se...\n",
       "2  2115579991                                                                                      vision meets robotics the kitti dataset we present a novel dataset captured from a vw station wagon for use in mobile robotics and autonomous driving research in total we recorded hours of traffic scenarios at hz using a variety of sensor modalities such as high resolution color and grayscale stereo cameras a velodyne 3d laser scanner and a high precision gps imu inertial navigation system the scenarios are diverse capturing real world traffic situations and range from freeways over rural areas to inner city scenes with many static and dynamic objects our data is calibrated synchronized and timestamped and we provide the rectified and raw image sequences our dataset also contains object labels in the form of 3d tracklets and we provide online benchmarks for stereo optical flow object detection and other tasks this paper describes our recording platform the data format and the utilities that we provide "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = pd.read_csv(\"../data/kit_expert_2017_papers.csv\")\n",
    "papers.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_parser = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neural network be the great'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"neural networks are the greatest\"\n",
    "tokens = spacy_parser(sent)\n",
    "\" \".join([token.lemma_ for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'keyword': 'liquid fluoride thorium reactor',\n",
       "  'paper_ids': ['1527740619'],\n",
       "  'level': 4,\n",
       "  'keyword_id': '30972296'},\n",
       " {'keyword': 'energy engineering',\n",
       "  'paper_ids': ['2056946625',\n",
       "   '2070521924',\n",
       "   '2254121180',\n",
       "   '2280790071',\n",
       "   '2593688536',\n",
       "   '2626060881',\n",
       "   '2759963175',\n",
       "   '612980819'],\n",
       "  'level': 3,\n",
       "  'keyword_id': '520343842'}]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/kit_expert_2017_keywords.json\", \"r\") as file:\n",
    "    keywords = json.load(file)\n",
    "keywords[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_chunk(model, keywords):\n",
    "    ap_list = []\n",
    "    for keyword_info in keywords:\n",
    "        query = keyword_info[\"keyword\"].lower().split(\" \")\n",
    "        relevant_ids = keyword_info[\"paper_ids\"]\n",
    "        ranked_ids = model.get_ranked_documents(query)[\"id\"]\n",
    "        ap_list.append(average_precision(ranked_ids, relevant_ids))\n",
    "    return ap_list\n",
    "def mean_average_percision(model, keywords, n_jobs):\n",
    "    pool = Pool(n_jobs)\n",
    "    worker_function = partial(handle_chunk, model)\n",
    "    work_chunks = np.array_split(keywords, n_jobs)\n",
    "    ap_list = np.concatenate(pool.map(worker_function, work_chunks))\n",
    "    return np.mean(ap_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(papers[\"id\"])\n",
    "corpus = list(papers[\"abstract\"].str.split(\" \"))\n",
    "models = [\n",
    "    (\"BM25 unigrams\", partial(BM25Retrieval, use_bigrams=False)),\n",
    "    (\"BM25 bigrams\", partial(BM25Retrieval, use_bigrams=True))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_keywords = [k for k in keywords if k[\"level\"]<=1]\n",
    "specific_keywords = [k for k in keywords if k[\"level\"]>=2]\n",
    "test_sets = [(\"general keywords\", general_keywords), (\"specific_keywords\", specific_keywords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 unigrams on general keywords :0.056651136157939215 mAP\n",
      "BM25 unigrams on specific_keywords :0.5145989750461202 mAP\n",
      "BM25 bigrams on general keywords :0.03751044645370631 mAP\n",
      "BM25 bigrams on specific_keywords :0.48493162987748234 mAP\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_factory in models:\n",
    "    model_instance = model_factory(ids, corpus)\n",
    "    for test_set_name, test_set in test_sets:\n",
    "        mAP = mean_average_percision(model_instance, test_set[:1000],2)\n",
    "        print(model_name + \" on \" + test_set_name + \" :\" + str(mAP) + \" mAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(corpus, min_count=1, threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['neural_network'], ['kitti_dataset']]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(phrases[[[\"neural\", \"network\"], [\"kitti\", \"dataset\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_model = BM25(phrases[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = phrases[\"kitti\".split(\" \")]\n",
    "scores = bm25_model.get_scores(query)\n",
    "sorted_score_indices = np.argsort(scores)[::-1]\n",
    "papers[\"id\"].iloc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_papers(papers, query):\n",
    "    paper_ids = papers[[\"id\"]]\n",
    "    query = phrases[query.split(\" \")]\n",
    "    paper_ids[\"score\"] = bm25_model.get_scores(query)\n",
    "    paper_ids = paper_ids.sort_values(by=\"score\", ascending=False)\n",
    "    paper_ids = paper_ids[paper_ids[\"score\"] > 0]\n",
    "    return paper_ids\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.81999861 10.16513453  9.46965468]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2150066425</td>\n",
       "      <td>are we ready for autonomous driving the kitti vision benchmark suite today visual recognition systems are still rarely employed in robotics applications perhaps one of the main reasons for this is the lack of demanding benchmarks that mimic such scenarios in this paper we take advantage of our autonomous driving platform to develop novel challenging benchmarks for the tasks of stereo optical flow visual odometry slam and 3d object detection our recording platform is equipped with four high resolution video cameras a velodyne laser scanner and a state of the art localization system our benchmarks comprise stereo and optical flow image pairs stereo visual odometry sequences of km length and more than 200k 3d object annotations captured in cluttered scenarios up to cars and pedestrians are visible per image results from state of the art algorithms reveal that methods ranking high on established datasets such as middlebury perform below average when being moved outside the laboratory t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26609</th>\n",
       "      <td>2972567833</td>\n",
       "      <td>estimating object shape and movement using local occupancy grid maps abstract estimating motion and shape of surrounding objects reliably and accurately is a fundamental challenge in the study of interactions between cooperative traffic participants this paper proposes a new approach that utilizes free space information obtained from a lidar sensor and object local grid maps in order to simultaneously estimate the shape and movement state of objects with arbitrary shape we evaluated our approach in several simulated scenarios and found that the movement and shape estimation results are very close to the ground truth finally we did a qualitative evaluation on real data extracted from the kitti benchmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>2100887497</td>\n",
       "      <td>road terrain detection avoiding common obstacle detection assumptions using sensor fusion obstacle detection is a fundamental task for advanced driver assistance systems adas and self driving cars several commercial systems like adaptive cruise controls and collision warning systems depend on them to notify the driver about a risky situation several approaches have been presented in the literature in the last years however most of them are limited to specific scenarios and restricted conditions in this paper we propose a robust sensor fusion based method capable of detecting obstacles in a wide variety of scenarios using a minimum number of parameters our approach is based on the spatial relationship on perspective images provided by a single camera and a 3d lidar experimental tests have been carried out in different conditions using the standard road kitti benchmark obtaining positive results</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 abstract\n",
       "0      2150066425  are we ready for autonomous driving the kitti vision benchmark suite today visual recognition systems are still rarely employed in robotics applications perhaps one of the main reasons for this is the lack of demanding benchmarks that mimic such scenarios in this paper we take advantage of our autonomous driving platform to develop novel challenging benchmarks for the tasks of stereo optical flow visual odometry slam and 3d object detection our recording platform is equipped with four high resolution video cameras a velodyne laser scanner and a state of the art localization system our benchmarks comprise stereo and optical flow image pairs stereo visual odometry sequences of km length and more than 200k 3d object annotations captured in cluttered scenarios up to cars and pedestrians are visible per image results from state of the art algorithms reveal that methods ranking high on established datasets such as middlebury perform below average when being moved outside the laboratory t...\n",
       "26609  2972567833                                                                                                                                                                                                                                                                                                 estimating object shape and movement using local occupancy grid maps abstract estimating motion and shape of surrounding objects reliably and accurately is a fundamental challenge in the study of interactions between cooperative traffic participants this paper proposes a new approach that utilizes free space information obtained from a lidar sensor and object local grid maps in order to simultaneously estimate the shape and movement state of objects with arbitrary shape we evaluated our approach in several simulated scenarios and found that the movement and shape estimation results are very close to the ground truth finally we did a qualitative evaluation on real data extracted from the kitti benchmark \n",
       "1775   2100887497                                                                                              road terrain detection avoiding common obstacle detection assumptions using sensor fusion obstacle detection is a fundamental task for advanced driver assistance systems adas and self driving cars several commercial systems like adaptive cruise controls and collision warning systems depend on them to notify the driver about a risky situation several approaches have been presented in the literature in the last years however most of them are limited to specific scenarios and restricted conditions in this paper we propose a robust sensor fusion based method capable of detecting obstacles in a wide variety of scenarios using a minimum number of parameters our approach is based on the spatial relationship on perspective images provided by a single camera and a 3d lidar experimental tests have been carried out in different conditions using the standard road kitti benchmark obtaining positive results "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_n(query, n):\n",
    "    scores = np.array(bm25_model.get_scores(phrases[query.split(\" \")]))\n",
    "    print(scores[np.argsort(scores)[-n:][::-1]])\n",
    "    return (papers.iloc[np.argsort(scores)[-n:][::-1]])\n",
    "get_top_n(\"kitti\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>paper_ids</th>\n",
       "      <th>level</th>\n",
       "      <th>keyword_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124961601</td>\n",
       "      <td>conical surface</td>\n",
       "      <td>['1970806100', '1984018685', '1996418911', '2006496599', '2032348195', '2038303896', '2040654611', '2059591544', '2071437655', '2228644465', '2330571978', '2414912487', '2791412389']</td>\n",
       "      <td>2</td>\n",
       "      <td>124961601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15122004</td>\n",
       "      <td>open learning</td>\n",
       "      <td>['2557711330']</td>\n",
       "      <td>4</td>\n",
       "      <td>15122004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2780556066</td>\n",
       "      <td>stereoelectronic effect</td>\n",
       "      <td>['2108143480']</td>\n",
       "      <td>2</td>\n",
       "      <td>2780556066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95942069</td>\n",
       "      <td>evolutionary arms race</td>\n",
       "      <td>['1980707088']</td>\n",
       "      <td>3</td>\n",
       "      <td>95942069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2777714038</td>\n",
       "      <td>simultaneous editing</td>\n",
       "      <td>['2756171889']</td>\n",
       "      <td>2</td>\n",
       "      <td>2777714038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _id                  keyword                                                                                                                                                                               paper_ids  level  keyword_id\n",
       "0   124961601          conical surface  ['1970806100', '1984018685', '1996418911', '2006496599', '2032348195', '2038303896', '2040654611', '2059591544', '2071437655', '2228644465', '2330571978', '2414912487', '2791412389']      2   124961601\n",
       "1    15122004            open learning                                                                                                                                                                          ['2557711330']      4    15122004\n",
       "2  2780556066  stereoelectronic effect                                                                                                                                                                          ['2108143480']      2  2780556066\n",
       "3    95942069   evolutionary arms race                                                                                                                                                                          ['1980707088']      3    95942069\n",
       "4  2777714038     simultaneous editing                                                                                                                                                                          ['2756171889']      2  2777714038"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = pd.read_csv(\"../data/kit_expert_2017_keywords.csv\")\n",
    "keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>paper_ids</th>\n",
       "      <th>level</th>\n",
       "      <th>keyword_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2781259782</td>\n",
       "      <td>uridine</td>\n",
       "      <td>['2323265909']</td>\n",
       "      <td>4</td>\n",
       "      <td>2781259782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17448</th>\n",
       "      <td>38087914</td>\n",
       "      <td>chain propagation</td>\n",
       "      <td>['174634246', '195630349']</td>\n",
       "      <td>4</td>\n",
       "      <td>38087914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19408</th>\n",
       "      <td>138111711</td>\n",
       "      <td>double hashing</td>\n",
       "      <td>['2253629710']</td>\n",
       "      <td>4</td>\n",
       "      <td>138111711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19539</th>\n",
       "      <td>31447003</td>\n",
       "      <td>spline interpolation</td>\n",
       "      <td>['2000239458', '2265976587', '591084388']</td>\n",
       "      <td>4</td>\n",
       "      <td>31447003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9450</th>\n",
       "      <td>125189844</td>\n",
       "      <td>inherent viscosity</td>\n",
       "      <td>['2065409933']</td>\n",
       "      <td>4</td>\n",
       "      <td>125189844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              _id               keyword                                  paper_ids  level  keyword_id\n",
       "273    2781259782               uridine                             ['2323265909']      4  2781259782\n",
       "17448    38087914     chain propagation                 ['174634246', '195630349']      4    38087914\n",
       "19408   138111711        double hashing                             ['2253629710']      4   138111711\n",
       "19539    31447003  spline interpolation  ['2000239458', '2265976587', '591084388']      4    31447003\n",
       "9450    125189844    inherent viscosity                             ['2065409933']      4   125189844"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = keywords[keywords[\"level\"] == 4].sample(1000, random_state=1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"paper_ids\"] = test_data[\"paper_ids\"].apply(lambda row: json.loads(row.replace(\"'\",'\"')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 886 ms, sys: 128 ms, total: 1.01 s\n",
      "Wall time: 995 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aps = []\n",
    "for i, row in test_data.iterrows():\n",
    "    query = row[\"keyword\"]\n",
    "    relevant_ids = row[\"paper_ids\"]\n",
    "    ranked_ids = get_ranked_papers(papers, query)[\"id\"]\n",
    "    aps.append(average_percision(ranked_ids, relevant_ids))\n",
    "print(np.mean(aps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.67137199 8.84735745 7.56296978 7.56296978 6.91187491 6.71370959\n",
      " 6.42217745 5.82328248 5.69349656 5.65909837]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16230    1966508755\n",
       "1115     2803010032\n",
       "4763     2145824827\n",
       "7663     2145530725\n",
       "10082    2607788411\n",
       "8039     2102458273\n",
       "23740    2972841205\n",
       "22450    2044871596\n",
       "7534     2787439179\n",
       "13203    2102969650\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_ids = get_top_n(\"east asia\", 10)[\"id\"]\n",
    "relevant_ids=[\"289032619\"]\n",
    "ranked_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2120361619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010318474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2099375819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2171395629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2089032619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          id\n",
       "0      1  2120361619\n",
       "1      2  2010318474\n",
       "2      3  2099375819\n",
       "3      4  2171395629\n",
       "4      5  2089032619"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_ids = ranked_ids.reset_index(drop=True).reset_index()\n",
    "ranked_ids[\"index\"] += 1\n",
    "ranked_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2120361619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2099375819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index          id\n",
       "0        0      1  2120361619\n",
       "1        2      3  2099375819"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = ranked_ids[ranked_ids[\"id\"].isin(relevant_ids)].reset_index()\n",
    "r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
