{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    tqdm.pandas()\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from evaluation import *\n",
    "from preprocessing import Corpus, BasicPreprocessing, BigramPreprocessor, SpacyPreprocessor, StopWordPreprocessor\n",
    "from retrieval_algorithms import TfIdfRetrievalAlgorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus using different preprocessing pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:preprocessing.pipeline:Start preprocessing pipeline \"basic_NoStopWords\" for file ../../data/kit_expert_2019_all_papers.csv.\n",
      "INFO:preprocessing.pipeline:Loaded cached preprocessed corpus from ../../data/kit_expert_2019_all_papers_basic_NoStopWords\n"
     ]
    }
   ],
   "source": [
    "base_file =  \"../../data/kit_expert_2019_all_papers.csv\"\n",
    "\n",
    "p = [BasicPreprocessing(), StopWordPreprocessor()]\n",
    "papers_basic = Corpus(base_file, p)\n",
    "\n",
    "# p = [BasicPreprocessing(), StopWordPreprocessor(), SpacyPreprocessor(lemmatization=\"all\")]\n",
    "# papers_basic_lemmatization_all = Corpus(base_file, p, load_from_cache=True, n_jobs=16)\n",
    "\n",
    "# p = [BasicPreprocessing(), StopWordPreprocessor(), SpacyPreprocessor(lemmatization=\"nouns\")]\n",
    "# papers_basic_lemmatization_nouns = Corpus(base_file, p, load_from_cache=True, n_jobs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load keywords to use as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/kit_expert_2019_all_keywords.json\", \"r\") as file:\n",
    "    keywords = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_keywords = [k for k in keywords if k[\"level\"]<=1]\n",
    "specific_keywords = [k for k in keywords if k[\"level\"]>=2 and len(k[\"paper_ids\"])>=10]\n",
    "\n",
    "general_keywords_val = (\"general keywords validation\", general_keywords[0:int(len(general_keywords)*0.8)])\n",
    "specific_keywords_val = (\"specific keywords validation\", specific_keywords[0:int(len(specific_keywords)*0.8)])\n",
    "general_keywords_test = (\"general keywords test\", general_keywords[int(len(general_keywords)*0.8):])\n",
    "specific_keywords_test = (\"specific keywords test\", specific_keywords[int(len(specific_keywords)*0.8):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 7972)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(general_keywords), len(specific_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test simple tf-idf models on unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_tfidf_models = [\n",
    "    (\"tf linear\", TfIdfRetrievalAlgorithm(max_ngram=1, use_idf=False, sublinear_tf=False, min_df=2), papers_basic),\n",
    "    (\"tf sublinear\", TfIdfRetrievalAlgorithm(max_ngram=1, use_idf=False, sublinear_tf=True, min_df=2), papers_basic),\n",
    "    (\"tf-idf linear\", TfIdfRetrievalAlgorithm(max_ngram=1, use_idf=True, sublinear_tf=False, min_df=2), papers_basic),\n",
    "    (\"tf-idf sublinear\", TfIdfRetrievalAlgorithm(max_ngram=1, use_idf=True, sublinear_tf=True, min_df=2), papers_basic),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_tfidf_results = train_evaluate_models(unigram_tfidf_models, [general_keywords_val, specific_keywords_val], n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for unigram tfidf models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">general keywords validation</th>\n",
       "      <th colspan=\"12\" halign=\"left\">specific keywords validation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@5</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@10</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@20</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R-prec</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mAP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bpref</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@5</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@10</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@20</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R-prec</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mAP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bpref</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tf linear</th>\n",
       "      <td>0.253</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf sublinear</th>\n",
       "      <td>0.277</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf linear</th>\n",
       "      <td>0.248</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf sublinear</th>\n",
       "      <td>0.267</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 general keywords validation                                                                              specific keywords validation                                                                             \n",
       "                                         p@5          p@10          p@20        R-prec           mAP         bpref                                 p@5          p@10          p@20        R-prec           mAP         bpref       \n",
       "                                         avg    err    avg    err    avg    err    avg    err    avg    err    avg    err                          avg    err    avg    err    avg    err    avg    err    avg    err    avg    err\n",
       "tf linear                              0.253  0.040  0.220  0.034  0.190  0.030  0.070  0.011  0.038  0.008  0.054  0.009                        0.482  0.009  0.423  0.008  0.350  0.007  0.314  0.007  0.306  0.007  0.292  0.007\n",
       "tf sublinear                           0.277  0.041  0.236  0.035  0.200  0.031  0.072  0.012  0.040  0.008  0.056  0.010                        0.588  0.009  0.518  0.008  0.426  0.007  0.386  0.006  0.375  0.007  0.362  0.007\n",
       "tf-idf linear                          0.248  0.039  0.215  0.033  0.185  0.029  0.071  0.011  0.037  0.008  0.054  0.009                        0.529  0.009  0.471  0.008  0.392  0.007  0.356  0.006  0.348  0.007  0.331  0.007\n",
       "tf-idf sublinear                       0.267  0.040  0.231  0.034  0.194  0.030  0.071  0.012  0.039  0.008  0.055  0.009                        0.601  0.009  0.538  0.008  0.451  0.007  0.416  0.006  0.411  0.007  0.393  0.007"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tfidf_results.to_csv(\"../../data/results/tfidf_unigram_results.csv\")\n",
    "print(\"Scores for unigram tfidf models:\")\n",
    "unigram_tfidf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "- Performs very bad on general keywords\n",
    "- Performs ok on specific keywords\n",
    "- Use of inverse document frequency improves result \n",
    "- Use of sublinear scaling of term frequency improves results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test tf-idf models on n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_tfidf_models = [\n",
    "    (\"tf-idf sublinear 2-gram\", TfIdfRetrievalAlgorithm(max_ngram=2, min_df=2), papers_basic),\n",
    "    (\"tf-idf sublinear 3-gram\", TfIdfRetrievalAlgorithm(max_ngram=3, min_df=2), papers_basic),\n",
    "    (\"tf-idf sublinear 4-gram\", TfIdfRetrievalAlgorithm(max_ngram=4, min_df=2), papers_basic),\n",
    "]\n",
    "ngram_tfidf_results = train_evaluate_models(ngram_tfidf_models, [general_keywords_val, specific_keywords_val], n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for ngram tfidf models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">general keywords validation</th>\n",
       "      <th colspan=\"12\" halign=\"left\">specific keywords validation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@5</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@10</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@20</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R-prec</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mAP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bpref</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@5</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@10</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@20</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R-prec</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mAP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bpref</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tf-idf sublinear 2-gram</th>\n",
       "      <td>0.299</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf sublinear 3-gram</th>\n",
       "      <td>0.299</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf sublinear 4-gram</th>\n",
       "      <td>0.298</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        general keywords validation                                                                            specific keywords validation                                                                             \n",
       "                                                p@5         p@10          p@20        R-prec           mAP         bpref                                p@5          p@10          p@20        R-prec           mAP         bpref       \n",
       "                                                avg   err    avg    err    avg    err    avg    err    avg    err    avg   err                          avg    err    avg    err    avg    err    avg    err    avg    err    avg    err\n",
       "tf-idf sublinear 2-gram                       0.299  0.04  0.265  0.036  0.213  0.031  0.076  0.012  0.043  0.008  0.060  0.01                        0.740  0.008  0.674  0.007  0.560  0.007  0.534  0.006  0.541  0.007  0.527  0.007\n",
       "tf-idf sublinear 3-gram                       0.299  0.04  0.260  0.035  0.212  0.031  0.076  0.012  0.043  0.008  0.060  0.01                        0.742  0.008  0.673  0.007  0.559  0.007  0.534  0.006  0.540  0.007  0.527  0.007\n",
       "tf-idf sublinear 4-gram                       0.298  0.04  0.258  0.035  0.211  0.031  0.076  0.012  0.042  0.008  0.059  0.01                        0.741  0.008  0.671  0.007  0.556  0.007  0.530  0.006  0.537  0.007  0.523  0.007"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_tfidf_results.to_csv(\"../../data/results/ngram_tfidf_results.csv\")\n",
    "print(\"Scores for ngram tfidf models:\")\n",
    "ngram_tfidf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "- No significant change for general keywords\n",
    "- Bigrams provide great improvement for specific keywords\n",
    "- 3 and 4-grams do not lead to significant further improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatization_tfidf_models = [\n",
    "    (\"tf-idf 2-gram lematization all\", TfIdfRetrievalAlgorithm(max_ngram=2, min_df=2), papers_basic_lemmatization_all),\n",
    "    (\"tf-idf 2-gram lematization nouns\", TfIdfRetrievalAlgorithm(max_ngram=2, min_df=2), papers_basic_lemmatization_nouns),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatization_tfidf_results = train_evaluate_models(lemmatization_tfidf_models, [general_keywords_val, specific_keywords_val], n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for lemmatization tfidf models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">general keywords validation</th>\n",
       "      <th colspan=\"12\" halign=\"left\">specific keywords validation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@5</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@10</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@20</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R-prec</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mAP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bpref</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@5</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@10</th>\n",
       "      <th colspan=\"2\" halign=\"left\">p@20</th>\n",
       "      <th colspan=\"2\" halign=\"left\">R-prec</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mAP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bpref</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "      <th>avg</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tf-idf 2-gram lematization all</th>\n",
       "      <td>0.295</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf 2-gram lematization nouns</th>\n",
       "      <td>0.298</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 general keywords validation                                                                             specific keywords validation                                                                             \n",
       "                                                         p@5          p@10          p@20        R-prec           mAP         bpref                                p@5          p@10          p@20        R-prec           mAP         bpref       \n",
       "                                                         avg    err    avg    err    avg    err    avg    err    avg    err    avg   err                          avg    err    avg    err    avg    err    avg    err    avg    err    avg    err\n",
       "tf-idf 2-gram lematization all                         0.295  0.039  0.253  0.034  0.206  0.030  0.079  0.012  0.044  0.008  0.061  0.01                        0.716  0.008  0.656  0.007  0.551  0.007  0.528  0.006  0.537  0.007  0.521  0.007\n",
       "tf-idf 2-gram lematization nouns                       0.298  0.039  0.256  0.034  0.213  0.031  0.081  0.013  0.045  0.008  0.062  0.01                        0.731  0.008  0.669  0.007  0.563  0.007  0.540  0.006  0.551  0.006  0.534  0.007"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prf_resultzation_tfidf_results.to_csv(\"../../data/results/lemmatization_tfidf_results.csv\")\n",
    "print(\"Scores for lemmatization tfidf models:\")\n",
    "lemmatization_tfidf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tfidf_model = TfIdfRetrievalAlgorithm(max_ngram=2, use_idf=True, sublinear_tf=True, min_df=2)\n",
    "best_tfidf_model.prepare(papers_basic_lemmatization_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../data/models/tfidf/tfidf_lemmatized_bigram.model\"\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(best_tfidf_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo relevance feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval_algorithms.prf_wrapper import PRFWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf = PRFWrapper(best_tfidf_model, 10, 10, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf.prepare(papers_basic_lemmatization_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6eca4f94aa14ec6b9942b984ad3e47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=6617.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prf_result = evaluate_model(prf, [general_keywords_val, specific_keywords_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfif_result = evaluate_model(best_tfidf_model, [general_keywords_val, specific_keywords_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper_retrieval-dhADrxe5",
   "language": "python",
   "name": "paper_retrieval-dhadrxe5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
