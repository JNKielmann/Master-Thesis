{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    tqdm.pandas()\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from evaluation import *\n",
    "from preprocessing import Corpus, BasicPreprocessing, BigramPreprocessor, SpacyPreprocessor, StopWordPreprocessor\n",
    "from retrieval_algorithms import TfIdfRetrievalAlgorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load corpus using different preprocessing pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:preprocessing.pipeline:Start preprocessing pipeline \"basic_NoStopWords\" for file ../../data/kit_expert_2019_all_papers.csv.\n",
      "INFO:preprocessing.pipeline:Loaded cached preprocessed corpus from ../../data/kit_expert_2019_all_papers_basic_NoStopWords\n",
      "INFO:preprocessing.pipeline:Start preprocessing pipeline \"basic_NoStopWords_spacy_lemmatization_all\" for file ../../data/kit_expert_2019_all_papers.csv.\n",
      "INFO:preprocessing.pipeline:Loaded cached preprocessed corpus from ../../data/kit_expert_2019_all_papers_basic_NoStopWords_spacy_lemmatization_all\n",
      "INFO:preprocessing.pipeline:Start preprocessing pipeline \"basic_NoStopWords_spacy_lemmatization_nouns\" for file ../../data/kit_expert_2019_all_papers.csv.\n",
      "INFO:preprocessing.pipeline:Loaded cached preprocessed corpus from ../../data/kit_expert_2019_all_papers_basic_NoStopWords_spacy_lemmatization_nouns\n"
     ]
    }
   ],
   "source": [
    "base_file =  \"../../data/kit_expert_2019_all_papers.csv\"\n",
    "\n",
    "p = [BasicPreprocessing(), StopWordPreprocessor()]\n",
    "papers_basic = Corpus(base_file, p)\n",
    "\n",
    "p = [BasicPreprocessing(), StopWordPreprocessor(), SpacyPreprocessor(lemmatization=\"all\")]\n",
    "papers_basic_lemmatization_all = Corpus(base_file, p, load_from_cache=True, n_jobs=16)\n",
    "\n",
    "p = [BasicPreprocessing(), StopWordPreprocessor(), SpacyPreprocessor(lemmatization=\"nouns\")]\n",
    "papers_basic_lemmatization_nouns = Corpus(base_file, p, load_from_cache=True, n_jobs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load keywords to use as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/kit_expert_2019_all_keywords.json\", \"r\") as file:\n",
    "    keywords = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_keywords = (\"general keywords\", [k for k in keywords if k[\"level\"]<=1])\n",
    "specific_keywords = (\"specific_keywords\", [k for k in keywords if k[\"level\"]>=2 and len(k[\"paper_ids\"])>=10][:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test simple tf-idf models on unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_tfidf_models = [\n",
    "    (\"tf linear\", TfIdfRetrievalAlgorithm(max_ngram=1, use_idf=False, sublinear_tf=False, min_df=2), papers_basic),\n",
    "    (\"tf sublinear\", TfIdfRetrievalAlgorithm(max_ngram=1, use_idf=False, sublinear_tf=True, min_df=2), papers_basic),\n",
    "    (\"tf-idf linear\", TfIdfRetrievalAlgorithm(max_ngram=1, use_idf=True, sublinear_tf=False, min_df=2), papers_basic),\n",
    "    (\"tf-idf sublinear\", TfIdfRetrievalAlgorithm(max_ngram=1, use_idf=True, sublinear_tf=True, min_df=2), papers_basic),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_tfidf_results = train_evaluate_models(unigram_tfidf_models, [general_keywords, specific_keywords], n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP scores for unigram tfidf models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">general keywords</th>\n",
       "      <th colspan=\"6\" halign=\"left\">specific_keywords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>p@5</th>\n",
       "      <th>p@10</th>\n",
       "      <th>p@20</th>\n",
       "      <th>R-prec</th>\n",
       "      <th>mAP</th>\n",
       "      <th>bpref</th>\n",
       "      <th>p@5</th>\n",
       "      <th>p@10</th>\n",
       "      <th>p@20</th>\n",
       "      <th>R-prec</th>\n",
       "      <th>mAP</th>\n",
       "      <th>bpref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tf linear</th>\n",
       "      <td>0.261</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf sublinear</th>\n",
       "      <td>0.283</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf linear</th>\n",
       "      <td>0.258</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf sublinear</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 general keywords                                    specific_keywords                                   \n",
       "                              p@5   p@10   p@20 R-prec    mAP  bpref               p@5   p@10   p@20 R-prec    mAP  bpref\n",
       "tf linear                   0.261  0.221  0.191  0.076  0.042  0.058             0.482  0.423  0.351  0.313  0.304  0.290\n",
       "tf sublinear                0.283  0.241  0.203  0.077  0.044  0.060             0.586  0.517  0.425  0.384  0.372  0.359\n",
       "tf-idf linear               0.258  0.224  0.191  0.077  0.042  0.059             0.533  0.473  0.394  0.355  0.348  0.330\n",
       "tf-idf sublinear            0.275  0.236  0.199  0.077  0.043  0.060             0.601  0.540  0.453  0.416  0.411  0.393"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"mAP scores for unigram tfidf models:\")\n",
    "unigram_tfidf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "- Performs very bad on general keywords\n",
    "- Performs ok on specific keywords\n",
    "- Use of inverse document frequency improves result \n",
    "- Use of sublinear scaling of term frequency improves results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test tf-idf models on n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_tfidf_models = [\n",
    "    (\"tf-idf sublinear 2-gram\", TfIdfRetrievalAlgorithm(max_ngram=2, min_df=2), papers_basic),\n",
    "    (\"tf-idf sublinear 3-gram\", TfIdfRetrievalAlgorithm(max_ngram=3, min_df=2), papers_basic),\n",
    "    (\"tf-idf sublinear 4-gram\", TfIdfRetrievalAlgorithm(max_ngram=4, min_df=2), papers_basic),\n",
    "]\n",
    "ngram_tfidf_results = train_evaluate_models(ngram_tfidf_models, [general_keywords, specific_keywords], n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP scores for ngram tfidf models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">general keywords</th>\n",
       "      <th colspan=\"6\" halign=\"left\">specific_keywords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>p@5</th>\n",
       "      <th>p@10</th>\n",
       "      <th>p@20</th>\n",
       "      <th>R-prec</th>\n",
       "      <th>mAP</th>\n",
       "      <th>bpref</th>\n",
       "      <th>p@5</th>\n",
       "      <th>p@10</th>\n",
       "      <th>p@20</th>\n",
       "      <th>R-prec</th>\n",
       "      <th>mAP</th>\n",
       "      <th>bpref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tf-idf sublinear 2-gram</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf sublinear 3-gram</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf sublinear 4-gram</th>\n",
       "      <td>0.302</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        general keywords                                    specific_keywords                                   \n",
       "                                     p@5   p@10   p@20 R-prec    mAP  bpref               p@5   p@10   p@20 R-prec    mAP  bpref\n",
       "tf-idf sublinear 2-gram            0.304  0.270  0.220  0.082  0.048  0.065             0.740  0.672  0.559  0.532  0.538  0.524\n",
       "tf-idf sublinear 3-gram            0.304  0.264  0.219  0.083  0.048  0.065             0.742  0.672  0.558  0.531  0.537  0.524\n",
       "tf-idf sublinear 4-gram            0.302  0.264  0.217  0.083  0.048  0.065             0.741  0.670  0.555  0.528  0.534  0.520"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"mAP scores for ngram tfidf models:\")\n",
    "ngram_tfidf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "- No significant change for general keywords\n",
    "- Bigrams provide great improvement for specific keywords\n",
    "- 3 and 4-grams do not lead to significant further improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatization_tfidf_models = [\n",
    "    (\"tf-idf 2-gram lematization all\", TfIdfRetrievalAlgorithm(max_ngram=2, min_df=2), papers_basic_lemmatization_all),\n",
    "    (\"tf-idf 2-gram lematization nouns\", TfIdfRetrievalAlgorithm(max_ngram=2, min_df=2), papers_basic_lemmatization_nouns),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatization_tfidf_results = train_evaluate_models(lemmatization_tfidf_models, [general_keywords, specific_keywords], n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP scores for lemmatization tfidf models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">general keywords</th>\n",
       "      <th colspan=\"6\" halign=\"left\">specific_keywords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>p@5</th>\n",
       "      <th>p@10</th>\n",
       "      <th>p@20</th>\n",
       "      <th>R-prec</th>\n",
       "      <th>mAP</th>\n",
       "      <th>bpref</th>\n",
       "      <th>p@5</th>\n",
       "      <th>p@10</th>\n",
       "      <th>p@20</th>\n",
       "      <th>R-prec</th>\n",
       "      <th>mAP</th>\n",
       "      <th>bpref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tf-idf 2-gram lematization all</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf 2-gram lematization nouns</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 general keywords                                    specific_keywords                                   \n",
       "                                              p@5   p@10   p@20 R-prec    mAP  bpref               p@5   p@10   p@20 R-prec    mAP  bpref\n",
       "tf-idf 2-gram lematization all              0.300  0.258  0.211  0.085  0.048  0.066             0.714  0.653  0.550  0.526  0.534  0.518\n",
       "tf-idf 2-gram lematization nouns            0.304  0.264  0.218  0.087  0.050  0.067             0.730  0.667  0.562  0.539  0.549  0.532"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"mAP scores for lemmatization tfidf models:\")\n",
    "lemmatization_tfidf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tfidf_model = TfIdfRetrievalAlgorithm(max_ngram=2, use_idf=True, sublinear_tf=True, min_df=2)\n",
    "best_tfidf_model.prepare(papers_basic_lemmatization_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/models/tfidf/tfidf_lemmatized_bigram.model\"\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(best_tfidf_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper_retrieval-dhADrxe5",
   "language": "python",
   "name": "paper_retrieval-dhadrxe5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
